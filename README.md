# EXPLICABILIDAD DE MODELOS PREDICTIVOS CON RANDOM FOREST
An√°lisis con SHAP y LIME sobre el dataset Social Network Ads
# Objetivo
Entrenar un modelo supervisado de clasificaci√≥n basado en Random Forest para predecir la variable Purchased, y aplicar t√©cnicas de explicabilidad (SHAP y LIME) con el fin de comprender c√≥mo las variables influyen en las decisiones del modelo, as√≠ como reflexionar sobre la transparencia, los riesgos √©ticos y las implicaciones sociales de su posible implementaci√≥n.

---

## üìä Dataset
Se utiliz√≥ el conjunto de datos **Social Network Ads**, el cual contiene informaci√≥n demogr√°fica y econ√≥mica de usuarios:

- Gender  
- Age  
- EstimatedSalary  
- Purchased (variable objetivo)

El dataset se encuentra disponible en la carpeta `data/`.

---

## üß† Metodolog√≠a

La metodolog√≠a empleada en este trabajo sigue un flujo t√≠pico de aprendizaje supervisado con √©nfasis en explicabilidad (XAI), estructurado para garantizar tanto el desempe√±o predictivo del modelo como la comprensi√≥n de sus decisiones.

### Exploraci√≥n de datos
Se realiz√≥ una inspecci√≥n inicial para verificar su estructura, tipos de datos y variable objetivo. Posteriormente, se llev√≥ a cabo un an√°lisis exploratorio de datos (EDA), incluyendo visualizaciones de la distribuci√≥n de la variable *Purchased* y el comportamiento de las variables *Age* y *EstimatedSalary*, tanto de forma general como segmentada por clase.

### Preprocesamiento
Como parte del preprocesamiento, la variable categ√≥rica *Gender* fue codificada en formato binario (0/1). No se aplic√≥ escalado de variables, ya que el modelo seleccionado (Random Forest) no lo requiere y mantener las variables en su escala original favorece la interpretabilidad de las t√©cnicas de explicabilidad utilizadas.

### Divisi√≥n de los datos
El conjunto de datos fue dividido en subconjuntos de entrenamiento y prueba utilizando una partici√≥n estratificada, con el objetivo de preservar la proporci√≥n de clases en ambos conjuntos. Se emple√≥ una divisi√≥n del 75 % para entrenamiento y 25 % para prueba (test_size = 0.25), permitiendo evaluar el desempe√±o del modelo sobre datos no utilizados durante el proceso de entrenamiento.

### Entrenamiento del modelo
Se entren√≥ un modelo **Random Forest Classifier** para un problema de clasificaci√≥n binaria, utilizando hiperpar√°metros b√°sicos y sin realizar procesos de ajuste complejo (tuning), priorizando la claridad metodol√≥gica y la interpretabilidad del modelo.

### Evaluaci√≥n del modelo
El desempe√±o del modelo fue evaluado mediante m√©tricas est√°ndar, incluyendo accuracy, matriz de confusi√≥n y reporte de clasificaci√≥n (precision, recall y F1-score), con el fin de verificar su capacidad predictiva antes de aplicar t√©cnicas de explicabilidad.

### T√©cnicas de explicabilidad (XAI)
Para analizar c√≥mo el modelo toma decisiones, se aplicaron t√©cnicas de inteligencia artificial explicable. En primer lugar, se utiliz√≥ **SHAP** para obtener explicaciones globales (importancia de variables) y locales (predicciones individuales). Posteriormente, se emple√≥ **LIME** para generar explicaciones locales adicionales y contrastar los resultados obtenidos con SHAP.

### An√°lisis √©tico
Finalmente, a partir de las explicaciones generadas, se realiz√≥ un an√°lisis reflexivo sobre la transparencia del modelo, la influencia de variables sensibles y los posibles riesgos √©ticos y sociales asociados a su implementaci√≥n.

---

## üìà Resultados principales

En el notebook principal del repositorio (`Deber_Grupal_S4.ipynb`) se presentan los resultados obtenidos a partir del entrenamiento del modelo y la aplicaci√≥n de t√©cnicas de explicabilidad. En particular, se destacan los siguientes aspectos:

- Desempe√±o adecuado del modelo Random Forest, con m√©tricas que evidencian una capacidad consistente para diferenciar entre las clases *Compra* y *No compra*.
- Identificaci√≥n de las variables **Age** y **EstimatedSalary** como las de mayor influencia en las decisiones del modelo, tanto a nivel global como local, mediante t√©cnicas SHAP.
- Explicaciones locales coherentes de predicciones individuales, obtenidas con SHAP y LIME, que permiten comprender c√≥mo distintas variables contribuyen a cada decisi√≥n.
- An√°lisis reflexivo sobre la transparencia del modelo, la presencia de posibles sesgos y los riesgos √©ticos asociados a su implementaci√≥n.

Las visualizaciones y explicaciones que respaldan estos resultados se muestran directamente en el notebook.

---

## üìÅ Estructura del repositorio
```text
grupal_S4/
‚îú‚îÄ‚îÄ data/          # Dataset utilizado
‚îÇ   ‚îî‚îÄ‚îÄ Social_Network_Ads.csv
‚îú‚îÄ‚îÄ notebooks/     # Notebook principal del an√°lisis
‚îÇ   ‚îî‚îÄ‚îÄ Deber_Grupal_S4.ipynb
‚îî‚îÄ‚îÄ README.md
```
---

## üé• Presentaci√≥n t√©cnica

Enlace a la presentaci√≥n t√©cnica donde se explica el problema abordado, la metodolog√≠a aplicada, las t√©cnicas de explicabilidad utilizadas, el an√°lisis comparativo y las conclusiones finales:

üëâ **ENLACE AL VIDEO:**  
[https://ENLACE_DEL_VIDEO](https://drive.google.com/file/d/177CxaCwWil_pvzZc916c1hXr0mueXaQt/view?usp=drive_link)
