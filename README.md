# Grupal_S4 â€“ Explicabilidad de Modelos Predictivos (XAI)

Repositorio correspondiente a la actividad **S4**, cuyo objetivo es entrenar un modelo predictivo supervisado y aplicar tÃ©cnicas de explicabilidad para analizar cÃ³mo el modelo toma decisiones, asÃ­ como reflexionar sobre aspectos Ã©ticos, sociales y de transparencia en sistemas de inteligencia artificial.

---

## ğŸ“Š Dataset
Se utilizÃ³ el conjunto de datos **Social Network Ads**, el cual contiene informaciÃ³n demogrÃ¡fica y econÃ³mica de usuarios:

- Gender  
- Age  
- EstimatedSalary  
- Purchased (variable objetivo)

El dataset se encuentra disponible en la carpeta `data/`.

---

## ğŸ§  MetodologÃ­a
El desarrollo de la actividad siguiÃ³ las siguientes etapas:

1. AnÃ¡lisis exploratorio de datos (EDA)
2. EvaluaciÃ³n de la calidad de los datos
3. Preprocesamiento de variables
4. Entrenamiento de un modelo predictivo supervisado
5. EvaluaciÃ³n del desempeÃ±o del modelo
6. AplicaciÃ³n de tÃ©cnicas de explicabilidad (XAI)
7. AnÃ¡lisis Ã©tico y reflexivo de los resultados obtenidos

Toda la metodologÃ­a y el anÃ¡lisis se documentan en el notebook principal del repositorio.

---

## ğŸ¤– Modelo predictivo
- **Tipo de problema:** ClasificaciÃ³n binaria  
- **Modelo utilizado:** Random Forest Classifier  
- **Variable objetivo:** Purchased  

El modelo fue evaluado mediante mÃ©tricas estÃ¡ndar, incluyendo accuracy, matriz de confusiÃ³n, precision, recall y F1-score, con el fin de verificar su desempeÃ±o antes de aplicar tÃ©cnicas de explicabilidad.

---

## ğŸ“ˆ Resultados principales
El modelo Random Forest obtuvo un **accuracy aproximado del 91 %** sobre el conjunto de prueba, mostrando un desempeÃ±o equilibrado entre las clases *Compra* y *No compra*. 

Los anÃ¡lisis de explicabilidad evidencian que las variables **Age** y **EstimatedSalary** son las que ejercen mayor influencia en las decisiones del modelo, tanto a nivel global como local. En contraste, la variable **Gender** presenta un impacto reducido, lo que disminuye el riesgo de sesgos directos asociados a esta caracterÃ­stica sensible.

Las explicaciones locales obtenidas mediante SHAP y LIME muestran coherencia en la interpretaciÃ³n de decisiones individuales, reforzando la confianza en el comportamiento del modelo.

---

## ğŸ” TÃ©cnicas de explicabilidad aplicadas (XAI)
Para analizar la toma de decisiones del modelo, se aplicaron las siguientes tÃ©cnicas de explicabilidad:

- **SHAP**
  - Explicabilidad global (importancia de variables)
  - Explicabilidad local (predicciones individuales)
- **LIME**
  - Explicaciones locales para casos concretos

Las visualizaciones generadas se encuentran en la carpeta `figures/`.

---

## âš–ï¸ Transparencia, sesgos y anÃ¡lisis Ã©tico
A partir de las tÃ©cnicas de explicabilidad, se analizÃ³ la transparencia del modelo, la influencia de variables sensibles, los posibles riesgos Ã©ticos y sociales de su implementaciÃ³n, asÃ­ como la importancia de incorporar explicabilidad en sistemas predictivos utilizados en contextos reales. Estas reflexiones se desarrollan dentro del notebook principal.

---

## ğŸ“ Estructura del repositorio
```text
grupal_S4/
â”œâ”€â”€ data/          # Dataset utilizado
â”‚   â””â”€â”€ Social_Network_Ads.csv
â”œâ”€â”€ notebooks/     # Notebook principal del anÃ¡lisis
â”‚   â””â”€â”€ S4_Explicabilidad_RandomForest_SHAP_LIME.ipynb
â”œâ”€â”€ figures/       # GrÃ¡ficos y visualizaciones XAI
â”‚   â”œâ”€â”€ eda_purchased_distribution.png
â”‚   â”œâ”€â”€ shap_global_summary.png
â”‚   â”œâ”€â”€ shap_global_bar.png
â”‚   â”œâ”€â”€ shap_local_compra.png
â”‚   â”œâ”€â”€ shap_local_no_compra.png
â”‚   â”œâ”€â”€ lime_local_compra.png
â”‚   â””â”€â”€ lime_local_no_compra.png
â””â”€â”€ README.md
